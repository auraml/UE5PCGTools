{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to load and link kernal in notebook\n",
    "!conda activate text_to_3d_env_llama3\n",
    "!pip install notebook\n",
    "!pip install ipykernel\n",
    "!python -m ipykernel install --user --name=mykernal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "!pip install --no-deps xformers \"trl<0.9.0\" peft accelerate bitsandbytes wandb\n",
    "!pip install torch --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SETUP MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unsloth: Please import Unsloth before bitsandbytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n",
      "File \u001b[0;32m~/anaconda3/envs/text_to_3d_env_llama3/lib/python3.10/site-packages/unsloth/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m MODULES_TO_CHECK:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please import Unsloth before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unsloth: Please import Unsloth before bitsandbytes."
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "from unsloth import FastLanguageModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Unsloth: Please import Unsloth before bitsandbytes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[1;32m      3\u001b[0m version \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m max_seq_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32768\u001b[39m \u001b[38;5;66;03m#32768 #2048  # Choose any! We auto support RoPE Scaling internally!\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/text_to_3d_env_llama3/lib/python3.10/site-packages/unsloth/__init__.py:26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m MODULES_TO_CHECK:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[0;32m---> 26\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsloth: Please import Unsloth before \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unsloth: Please import Unsloth before bitsandbytes."
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "\n",
    "version = \"v6\"\n",
    "max_seq_length = 32768 #32768 #2048  # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "output_dir = f\"arjuntheprogrammer/llama3-8B-racks-v6{version}\"\n",
    "\n",
    "# from transformers import AutoModel, AutoTokenizer\n",
    "# model_id = \"arjuntheprogrammer/llama3-8B-racks-v6\"\n",
    "# model = AutoModel.from_pretrained(model_id)\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = output_dir, # YOUR MODEL YOU USED FOR TRAINING\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    ")\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INFERENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bitsandbytes'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 41\u001b[0m\n\u001b[0;32m     15\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mCreate a 3D racks cluster system with the following specifications:\u001b[39m\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m \u001b[38;5;124m- The cluster consists of 3 row and 2 column with a distance of 200 units between rows and 300 units between columns.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munsloth\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[0;32m     42\u001b[0m     model, tokenizer \u001b[38;5;241m=\u001b[39m FastLanguageModel\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m     43\u001b[0m         model_name \u001b[38;5;241m=\u001b[39m output_dir, \u001b[38;5;66;03m# YOUR MODEL YOU USED FOR TRAINING\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         max_seq_length \u001b[38;5;241m=\u001b[39m max_seq_length,\n\u001b[0;32m     45\u001b[0m         dtype \u001b[38;5;241m=\u001b[39m dtype,\n\u001b[0;32m     46\u001b[0m         load_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit,\n\u001b[0;32m     47\u001b[0m     )\n\u001b[0;32m     48\u001b[0m     FastLanguageModel\u001b[38;5;241m.\u001b[39mfor_inference(model) \u001b[38;5;66;03m# Enable native 2x faster inference\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dev\\.conda\\envs\\text_to_3d_env_llama3\\lib\\site-packages\\unsloth\\__init__.py:80\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# Try loading bitsandbytes and triton\u001b[39;00m\n\u001b[1;32m---> 80\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mbitsandbytes\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mbnb\u001b[39;00m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtriton\u001b[39;00m\n\u001b[0;32m     83\u001b[0m libcuda_dirs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bitsandbytes'"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "input_text = \"\"\"Create a 3D racks cluster system with the following specifications:\n",
    "\n",
    "- The cluster consists of 3 row and 2 column with a distance of 200 units between rows and 300 units between columns.\n",
    "- Inside the cluster, there is a rack with 3 row and 1 column.\n",
    "- The rack contains trays where pallets are placed. Each pallet has an offset of x: 12, y: 0, z: 11 units.\n",
    "\n",
    "Start building the cluster system based on these dimensions and arrangements.\n",
    "\n",
    "Following are the different assets with their dimensions in JSON format which you can use to build the 3D environment:\n",
    "{\n",
    "  \"SM_Box_2\": {\"id\": 0, \"dimensions\": [42, 90, 50]},\n",
    "  \"SM_Box_3\": {\"id\": 1, \"dimensions\": [20, 40, 20]},\n",
    "  \"SM_Box_4\": {\"id\": 2, \"dimensions\": [20, 20, 20]},\n",
    "  \"SM_Box_5\": {\"id\": 3, \"dimensions\": [40, 40, 40]},\n",
    "  \"SM_Box_6\": {\"id\": 4, \"dimensions\": [40, 40, 20]},\n",
    "  \"SM_Box_7\": {\"id\": 5, \"dimensions\": [40, 80, 20]},\n",
    "  \"SM_Box_8\": {\"id\": 6, \"dimensions\": [42, 90, 30]},\n",
    "  \"SM_Pallet\": {\"id\": 7, \"dimensions\": [121, 101, 12]},\n",
    "  \"SM_Rack_Frame\": {\"id\": 8, \"dimensions\": [10, 100, 128]},\n",
    "  \"SM_Rack_Tray\": {\"id\": 9, \"dimensions\": [288, 100, 16]}\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    prompt_template.format(\n",
    "        input_text,\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(\n",
    "    **inputs, streamer = text_streamer,\n",
    "    max_new_tokens = max_seq_length,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mykernel",
   "language": "python",
   "name": "mykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
